{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 10:31:20.583216: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-30 10:31:20.775476: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-30 10:31:20.777221: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 10:31:21.575812: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "[nltk_data] Downloading package wordnet to /home/jj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /home/jj/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jj/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /home/jj/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jj/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "100%|██████████| 60001/60001 [02:54<00:00, 344.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from generator import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command = \"!generate ass\"\n",
    "# content_generator(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Activation, TimeDistributed, Softmax, TextVectorization, Reshape, RepeatVector, Conv1D, Bidirectional, AveragePooling1D, UpSampling1D, Embedding, Concatenate, GlobalAveragePooling1D, LSTM, Multiply\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.layers import Input, TextVectorization\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 10:58:28.465366: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [259,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 9, 15)             75000     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 15)                1860      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5000)              80000     \n",
      "                                                                 \n",
      " softmax_5 (Softmax)         (None, 5000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,860\n",
      "Trainable params: 156,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'crawler_data.csv'\n",
    "df = pd.read_csv(DATASET)\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices(df)\n",
    "\n",
    "vocab_size = 5000\n",
    "vectorize_layer = TextVectorization(max_tokens=vocab_size, output_sequence_length=10)\n",
    "vectorize_layer.adapt(ds)\n",
    "\n",
    "def separar_ultimo_token(x):\n",
    "    x_ = vectorize_layer(x)\n",
    "    x_ = x_[:,:-1]\n",
    "    y_ = x_[:,-1:]\n",
    "    return x_, y_\n",
    "\n",
    "def predict_word(seq_len, latent_dim, vocab_size):\n",
    "    input_layer = Input(shape=(seq_len-1,))\n",
    "    x = input_layer\n",
    "    x = Embedding(vocab_size, latent_dim, name='embedding', mask_zero=True)(x)\n",
    "    x = LSTM(latent_dim, kernel_initializer='glorot_uniform')(x)\n",
    "    latent_rep = x\n",
    "    x = Dense(vocab_size)(x)\n",
    "    x = Softmax()(x)\n",
    "    return Model(input_layer, x), Model(input_layer, latent_rep)\n",
    "\n",
    "predictor, latent = predict_word(10, 15, vocab_size)\n",
    "predictor.summary()\n",
    "#opt = keras.optimizers.SGD(learning_rate=1, momentum=0.9)\n",
    "opt = keras.optimizers.Nadam(learning_rate=0.1)\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "    ignore_class=1,\n",
    "    name=\"sparse_categorical_crossentropy\",\n",
    ")\n",
    "\n",
    "predictor.compile(loss=loss_fn, optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  1/259 [..............................] - ETA: 32s - loss: 8.4003 - accuracy: 0.3333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2023-05-30 10:59:55.318426: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [259,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259/259 [==============================] - 13s 50ms/step - loss: 2.4579 - accuracy: 0.6564\n",
      "Epoch 2/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 1.6273 - accuracy: 0.6937\n",
      "Epoch 3/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 1.3197 - accuracy: 0.7207\n",
      "Epoch 4/20\n",
      "259/259 [==============================] - 13s 49ms/step - loss: 1.3377 - accuracy: 0.7104\n",
      "Epoch 5/20\n",
      "259/259 [==============================] - 13s 49ms/step - loss: 1.2284 - accuracy: 0.7272\n",
      "Epoch 6/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 1.0507 - accuracy: 0.7516\n",
      "Epoch 7/20\n",
      "259/259 [==============================] - 13s 49ms/step - loss: 1.1285 - accuracy: 0.7284\n",
      "Epoch 8/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 1.1451 - accuracy: 0.7503\n",
      "Epoch 9/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 1.1209 - accuracy: 0.7619\n",
      "Epoch 10/20\n",
      "259/259 [==============================] - 13s 49ms/step - loss: 0.8634 - accuracy: 0.7773\n",
      "Epoch 11/20\n",
      "259/259 [==============================] - 13s 49ms/step - loss: 0.7588 - accuracy: 0.7941\n",
      "Epoch 12/20\n",
      "259/259 [==============================] - 13s 49ms/step - loss: 0.6883 - accuracy: 0.8057\n",
      "Epoch 13/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 0.7051 - accuracy: 0.7915\n",
      "Epoch 14/20\n",
      "259/259 [==============================] - 13s 51ms/step - loss: 0.5405 - accuracy: 0.8314\n",
      "Epoch 15/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 0.6430 - accuracy: 0.8314\n",
      "Epoch 16/20\n",
      "259/259 [==============================] - 13s 51ms/step - loss: 0.7174 - accuracy: 0.8069\n",
      "Epoch 17/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 0.6871 - accuracy: 0.8121\n",
      "Epoch 18/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 0.4688 - accuracy: 0.8443\n",
      "Epoch 19/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 0.4559 - accuracy: 0.8443\n",
      "Epoch 20/20\n",
      "259/259 [==============================] - 13s 50ms/step - loss: 0.5175 - accuracy: 0.8417\n"
     ]
    }
   ],
   "source": [
    "# series = pd.DataFrame(df[\"body\"])\n",
    "\n",
    "# ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "\n",
    "# # series = pd.Series(series.all())\n",
    "# series\n",
    "\n",
    "# series = series.dropna()\n",
    "# series = series.drop_duplicates()\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "history = predictor.fit(ds.map(separar_ultimo_token), epochs=20, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "[[3.9052212e-04 1.7625330e-09 2.7955217e-02 ... 1.7424109e-09\n",
      "  1.7431023e-09 1.7308673e-09]]\n",
      "tf.Tensor(762, shape=(), dtype=int64)\n",
      "jump\n"
     ]
    }
   ],
   "source": [
    "pred = predictor.predict(vectorize_layer([\"eu gosto de\"])[:,:-1])\n",
    "print(pred)\n",
    "idx = tf.argmax(pred, axis=1)[0]\n",
    "print(idx)\n",
    "word = vectorize_layer.get_vocabulary()[idx]\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "home\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "content\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "main\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "you\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "меню\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'brasil  home content main you меню          '"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def beam_search_predizer(entrada, numero_de_predicoes, modelo, vectorize_layer, beam_size):\n",
    "    frase = entrada\n",
    "    contexto = frase  # Contexto deslizante\n",
    "    for n in range(numero_de_predicoes):\n",
    "        pred = modelo.predict(vectorize_layer([contexto])[:, :-1])\n",
    "\n",
    "        # Beam search\n",
    "        candidates = []\n",
    "        for _ in range(beam_size):\n",
    "            # Select top candidate from the predictions\n",
    "            idx = np.argmax(pred, axis=1)[0]\n",
    "            word = vectorize_layer.get_vocabulary()[idx]\n",
    "\n",
    "            # Check if the word is already in the sentence\n",
    "            if word not in frase.split():\n",
    "                candidates.append((word, pred[0, idx]))\n",
    "\n",
    "            # Set the probability of the selected word to 0\n",
    "            pred[0, idx] = 0\n",
    "\n",
    "        # Sort candidates based on probability in descending order\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Select the top candidate as the next word\n",
    "        word = candidates[0][0]\n",
    "\n",
    "        frase = frase + \" \" + word\n",
    "        contexto = contexto + \" \" + word\n",
    "        contexto = ' '.join(contexto.split()[1:])\n",
    "        print(word)\n",
    "\n",
    "    return frase\n",
    "\n",
    "\n",
    "beam_search_predizer(\"brasil \", 15, predictor, vectorize_layer, beam_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " brasil\n"
     ]
    }
   ],
   "source": [
    "command = \"!generate: brasil\"\n",
    "\n",
    "match = re.match(r\"!generate:(.+)\", command)\n",
    "print(match.group(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 11:47:53.505034: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-30 11:47:53.530616: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-30 11:47:53.530980: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 11:47:54.130815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "2023-05-30 11:47:54.852500: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-05-30 11:47:54.890378: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [259,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9)]               0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 9, 15)             75000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 15)                1860      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5000)              80000     \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 5000)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 156,860\n",
      "Trainable params: 156,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/structured_function.py:254: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n",
      "2023-05-30 11:47:55.828806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [259,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 53/259 [=====>........................] - ETA: 10s - loss: 2.3645 - accuracy: 0.6352"
     ]
    }
   ],
   "source": [
    "from generator import content_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(content_generator(\"!generate: brasil\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
