{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jj/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /home/jj/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jj/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'crawler_data.csv'\n",
    "df = pd.read_csv(DATASET)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(df['body'])\n",
    "\n",
    "\n",
    "#print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buscar(palavras, indice):\n",
    "    assert type(palavras)==list\n",
    "    resultado = dict()\n",
    "    for p in palavras:\n",
    "        if p in indice.keys():\n",
    "            for documento in indice[p].keys():\n",
    "                if documento not in resultado.keys():\n",
    "                    resultado[documento] = indice[p][documento]\n",
    "                else:\n",
    "                    resultado[documento] += indice[p][documento]\n",
    "    return resultado\n",
    "\n",
    "#2 \n",
    "def n_relevantes(result_busca, n):\n",
    "    res = []\n",
    "    for key in result_busca.keys():\n",
    "        res.append( (result_busca[key], key)) \n",
    "\n",
    "    res = sorted(res, reverse= True)[0 : n]\n",
    "\n",
    "    return res\n",
    "\n",
    "#3\n",
    "def query(q_str, n, index):\n",
    "\n",
    "    words = re.findall('\\w+', q_str)\n",
    "    res = buscar(words, index)\n",
    "    res_n = n_relevantes(res, n)\n",
    "    return res_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58465/58465 [02:53<00:00, 337.44it/s]\n"
     ]
    }
   ],
   "source": [
    "index = dict()\n",
    "\n",
    "for w in tqdm(vectorizer.vocabulary_.keys()):\n",
    "    index[w] = dict()\n",
    "    for j in range(tfidf.shape[0]):\n",
    "        if tfidf[j, vectorizer.vocabulary_[w]] > 0:\n",
    "            index[w][j] = tfidf[j, vectorizer.vocabulary_[w]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_search(command):\n",
    "    match = re.match(r\"!search (.+)\", command)\n",
    "\n",
    "    term = match.group(1)\n",
    "    #aqui usamos tudo acima para pegar o documento com maior tf-idf, com indice invertido\n",
    "    result = query(term, 1, index)\n",
    "    print(result)\n",
    "\n",
    "    if result:\n",
    "        # print(result[0][1])\n",
    "        url = df.loc[result[0][1]].url\n",
    "        # print(url)\n",
    "        return url\n",
    "    \n",
    "    return \"Nao Encontrado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.5562452956285775, 173)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/search?channel=fs&client=ubuntu&q=wikipedia+dubai'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_search(\"!search dubai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wn_search(command):\n",
    "    url = 'none'\n",
    "    max_value = 0\n",
    "    \n",
    "    match = re.match(r\"!wn_search (.+)\", command)\n",
    "\n",
    "    term = match.group(1)\n",
    "\n",
    "    synsets = wordnet.synsets(term, lang='por')\n",
    "    print([syn for syn in synsets])\n",
    "    print([syn.name() for syn in synsets])\n",
    "    print([syn.definition() for syn in synsets])\n",
    "\n",
    "    #aqui usamos tudo acima para pegar o documento com maior tf-idf, com indice invertido\n",
    "    result = query(term, 1, index)\n",
    "    print(result)\n",
    "\n",
    "    if result:\n",
    "        url = df.loc[result[0][1]].url\n",
    "        max_value = result[0][0]\n",
    "   \n",
    "    for syn in synsets:\n",
    "\n",
    "        definition = syn.definition()\n",
    "        result = query(definition, 1, index)\n",
    "\n",
    "        if result:\n",
    "            value = result[0][0]\n",
    "\n",
    "            if value > max_value:\n",
    "                url = df.loc[result[0][1]].url\n",
    "\n",
    "\n",
    "    if url != 'none':\n",
    "        print(url)\n",
    "        return url\n",
    "    \n",
    "    return \"Nao Encontrado\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('duck.n.01'), Synset('drake.n.02'), Synset('duck.n.03')]\n",
      "['duck.n.01', 'drake.n.02', 'duck.n.03']\n",
      "['small wild or domesticated web-footed broad-billed swimming bird usually having a depressed body and short legs', 'adult male of a wild or domestic duck', 'flesh of a duck (domestic or wild)']\n",
      "[]\n",
      "https://species.wikimedia.org/wiki/Main_Page\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://species.wikimedia.org/wiki/Main_Page'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn_search(\"!wn_search pato\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
